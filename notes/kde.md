# Using kernel density estimation to search inside of long texts

Back when I was working at Virginia, between 2011 and the first half of 2014, Wayne Graham and I were tasked with the (long, difficult) process of moving a large collection of old text encoding projects that had been developed under the auspices of the eText Center onto a more modern server architecture. The eText Center was one of the earliest, longest-running, and most venerable digital humanities outfits at Virgnia (or really anwhere for that matter). It was one of the real trailblazers during what might now be thought of as the "first wave" of digital humanities work in the 90's and aughts, when most of the work was still centered around the task of digitizing texts and finding efficient and useful ways to make them available on the internet. At core, it was a TEI encoding shop, and most of the projects took the form of TEI-backed editions of texts or small groups of texts, which were carefully edited and wrapped up in the form of interpretive websites that provided really comprehensive and rich views of the documents.

For 15 years, from 1992 through 2007, almost all of the projects produced by the center had been put on a single physical server in the library, which, by the time I showed up in 2011, was ancient and literally out of warranty, which made it a kind of ticking time bomb from a systems administration standpoint. All of the projects had to get moved onto the library's up-to-date, production servers, but, as it turns out, this is no small task. In fact, the migration process had already been underway in some for or another for almost three years before I even got there, and Wayne and I were really just wrapping up the last little odds and ends. For the most part, the projects weren't hugely complicated from a technological standpoint - in most cases, they consisted of a core set of TEI documents, which was the core work product, and a set of XSLT stylesheets to transform the XML into HTML for presentation on the web. For each projects, we grepped through all the XML files and replaced harcoded links to the old Etext website, plugged the TEI -> HTML generation scripts into the Capistrano-backed deployment rig that powered the modern infrastructure, and just shovelled all the files onto the new servers.

Again and again, though, there was one big sticking point - as you might expect for projects that, at core, are digital editions of primary texts designed with researchers in mind, many of the projects had some kind of full-text searching functionality, which is a much bigger headache to migrate than nice, static XML/XSLT files. To make things worse, many of the search interfaces were built on top of an ancient piece of software for searching inside of XML documents called XXX, which is now completely defunct, meaning that we had to rewrite the search utilities completely from scratch for every project. Fortunately, open-source search technologies are vastly better now than there were in the mid-90's, and we took a pretty kosher approach to the problem - write some little scripts to split up the TEI documents into little chunks (usually just breaking on some roughly paragraph- or section-level unit of markup, like `<div2>` or `<p>`, depending on how the TEI was structured, and index all of the little sub-documents in Solr, which could then be queried by a simple search interface that exposed all of the built-in goodies that come with Solr - hit-highlighting, faceting, pagination, etc.

This is an easy and effective solution to the problem, and Solr's hit-highlighting did a good job of replicating the functionality of the old software, which was basically generated a stack of keyword-in-context concordance results. But, from a kind of philosophical standpoint, something about this irked me. It seemed obtuse, in some vague way, or at least less-than-optimal. I couldn't really put a finger on why, at first, but after rolling it around in my head for a while I realized that the problem was actually kind of large and fundamental, something far too open-ended to be tackled in the context of the migrations. Really, we were chafing up against the limitations of what is arguably the basic unit of organization in information retrieval - the idea of the "document."

A document is basically a little atom of content, mixed in with lots of other similarly-strucutred atoms of content (the "corpus" or "document set") that you might want to find and do something with. This idea is so ubiquitous - and, in most cases, so spectacularly useful - that barely needs to be rehearsed. Documents are everywhere, and underpin basically all modern information systems. Web pages are documents. This blog post is a document. Tweets, product listings, user profiles, Omeka items, Neatline records - all documents. A key feature of documents defined in this way, though, is that they are fundamentally thought of as being discrete and self-contained - when you have some kind of query, something you're looking for, something you're curious about, a piece of information that you want to find - the assumption is that the answer lies inside exactly of one of the documents - or, at least, exactly one document contains the _best_ answer to the question. The task of searching, then, becomes conceptually simple - given some query, find a subset of the documents that are relevant to the query. Then, order that subset of documents so that the most relevant document is at the "top" of the results, and the documents become increasingly less relevant as you scroll down through the stack. The assumption is that there's one document that is the _best_ or _correct_ "answer" to the query, and that the job of the information system is to pick out that document.

In a large majority cases, this works great. If I go to the digital catalog search interface in a library and type in "War and Peace," I want to find ... _War and Peace_ - one, particular "document" in the library. Or, more likely, you might not know exactly which document you want - if I'm programming, and run into some kind of problem and paste the error output into Google, I want to find the one, individual page out in the ether of the internet that tells me what's wrong and exactly how to fix it. I don't care if it's a StackOverflow answer, or a thread on Google group, or some random blog post - I just want the best, the most relevant, the most informative resource about the topic. Or, if I go to Amazon, and type in "digital camera" - I don't know which exact camera I want, and, in this case, I'm probably most interested in comparing different options against one another. But again, fundamentally, the final _answer_, the final _result_ of the query, however the information system gets me there, will be one particular camera, the best camera, the camera that I decide to buy.

The problem, of course, is that this modeling of the problem completely breaks down when applied to literary texts, and the kinds of questions that are interesting to ask about them. Say you study Shakespeare. Where do the "documents" begin and end?



Is each individual play a separate


In a simplistic and naive sense, you could say that each play is a separate document, fold the sonnets together (and maybe some of the other early poetry) into a document,



In information retrieval, a document is a discrete little packet of information - a cluster, a nodule, a data point that can be manipulated and analyzed as a single, unified entity. Documents aren't considered to be completely homogenous - in topic modelling, for example, documents are understood to have the ability to exhibit multiple topics, for example, to be about more than one thing. But, fundamentally, a document is the smallest unit of analysis

But this runs completely counter to the experience of a literary text, which fundemtanlly exists an an a progression, a narrative, a textual _interval_ that begins at the first word of the text and extends - both in a typographical and structural sense, and in a temporal sense, for any individual reading experience - to the last word of the text. This experience of a text as a space or an interval, a one-dimensional axis that is
